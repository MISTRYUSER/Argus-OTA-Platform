package main

import (
	"context"
	"database/sql"
	"fmt"
	"log"
	"os"
	"os/signal"
	"syscall"
	"time"

	"github.com/xuewentao/argus-ota-platform/internal/application"
	"github.com/xuewentao/argus-ota-platform/internal/infrastructure/kafka"
	"github.com/xuewentao/argus-ota-platform/internal/infrastructure/postgres"
	redisinfra "github.com/xuewentao/argus-ota-platform/internal/infrastructure/redis"
	"github.com/xuewentao/argus-ota-platform/internal/messaging"
	_ "github.com/lib/pq"
)

func main() {
	ctx := context.Background()

	// 1. åˆå§‹åŒ– PostgreSQL
	db := initDB()

	// 2. åˆå§‹åŒ– Redis
	redisClient := initRedis(ctx)

	// 3. åˆå§‹åŒ– Kafka Producerï¼ˆå‘å¸ƒäº‹ä»¶ï¼‰
	kafkaProducer := initKafkaProducer()

	// 4. åˆå§‹åŒ– Kafka Consumerï¼ˆæ¶ˆè´¹äº‹ä»¶ï¼‰
	kafkaConsumer, err := kafka.NewKafkaEventConsumer(
		[]string{"localhost:9092"},
		"orchestrator-group", // Consumer Group ID
	)
	if err != nil {
		log.Fatalf("Failed to create Kafka consumer: %v", err)
	}

	// 5. åˆå§‹åŒ– Repository
	batchRepo := postgres.NewPostgresBatchRepository(db)

	// 6. åˆå§‹åŒ– OrchestrateService
	orchestrateService := application.NewOrchestrateService(
		batchRepo,
		redisClient,
		kafkaProducer,
	)

	// 7. å¯åŠ¨ Kafka Consumer
	topics := []string{"batch-events"}

	log.Println("========================================")
	log.Println("ğŸš€ Orchestrator started successfully!")
	log.Printf("ğŸ“¡ Consuming topic: %s", topics[0])
	log.Printf("ğŸ“¦ Consumer Group: orchestrator-group")
	log.Println("========================================")

	// 8. ä¼˜é›…å…³é—­
	sigCh := make(chan os.Signal, 1)
	signal.Notify(sigCh, syscall.SIGINT, syscall.SIGTERM)

	// åœ¨åå° goroutine ä¸­æ¶ˆè´¹æ¶ˆæ¯
	go func() {
		if err := kafkaConsumer.Subscribe(ctx, topics, orchestrateService.HandleMessage); err != nil {
			log.Printf("Consumer error: %v", err)
		}
	}()

	// ç­‰å¾…ç³»ç»Ÿä¿¡å·
	<-sigCh
	log.Println("\nğŸ›‘ Shutting down Orchestrator...")

	// å…³é—­ Kafka Consumer
	if err := kafkaConsumer.Close(); err != nil {
		log.Printf("Failed to close Kafka consumer: %v", err)
	}

	// å…³é—­ Kafka Producer
	if err := kafkaProducer.Close(); err != nil {
		log.Printf("Failed to close Kafka producer: %v", err)
	}

	// å…³é—­ Redis
	if err := redisClient.Close(); err != nil {
		log.Printf("Failed to close Redis: %v", err)
	}

	// å…³é—­ PostgreSQL
	if err := db.Close(); err != nil {
		log.Printf("Failed to close PostgreSQL: %v", err)
	}

	log.Println("âœ… Orchestrator stopped gracefully")
}

// initDB åˆå§‹åŒ– PostgreSQL è¿æ¥
func initDB() *sql.DB {
	// ä»ç¯å¢ƒå˜é‡è¯»å–é…ç½®
	dbHost := getEnv("DB_HOST", "localhost")
	dbPort := getEnv("DB_PORT", "5432")
	dbUser := getEnv("DB_USER", "argus")
	dbPassword := getEnv("DB_PASSWORD", "argus_password")
	dbName := getEnv("DB_NAME", "argus_ota")

	// æ„å»º DSN
	dsn := fmt.Sprintf("host=%s port=%s user=%s password=%s dbname=%s sslmode=disable",
		dbHost, dbPort, dbUser, dbPassword, dbName)

	// è¿æ¥æ•°æ®åº“
	db, err := sql.Open("postgres", dsn)
	if err != nil {
		log.Fatalf("Failed to open database: %v", err)
	}

	// é…ç½®è¿æ¥æ± 
	db.SetMaxOpenConns(25)
	db.SetMaxIdleConns(5)
	db.SetConnMaxIdleTime(5 * time.Minute)
	db.SetConnMaxLifetime(5 * time.Minute)

	// Ping æµ‹è¯•è¿æ¥
	ctx, cancel := context.WithTimeout(context.Background(), 5*time.Second)
	defer cancel()

	if err := db.PingContext(ctx); err != nil {
		log.Fatalf("Failed to ping database: %v", err)
	}

	log.Printf("[PostgreSQL] Connected to %s:%s/%s", dbHost, dbPort, dbName)
	return db
}

// initRedis åˆå§‹åŒ– Redis è¿æ¥
func initRedis(ctx context.Context) *redisinfra.RedisClient {
	redisAddr := getEnv("REDIS_ADDR", "localhost:6379")
	redisPassword := getEnv("REDIS_PASSWORD", "")

	redisClient, err := redisinfra.NewRedisClient(ctx, redisAddr, redisPassword, 0)
	if err != nil {
		log.Fatalf("Failed to create Redis client: %v", err)
	}

	return redisClient
}

// initKafkaProducer åˆå§‹åŒ– Kafka Producer
func initKafkaProducer() messaging.KafkaEventPublisher {
	brokers := []string{getEnv("KAFKA_BROKERS", "localhost:9092")}
	topic := getEnv("KAFKA_TOPIC", "batch-events")

	producer, err := kafka.NewKafkaEventProducer(brokers, topic)
	if err != nil {
		log.Fatalf("Failed to create Kafka producer: %v", err)
	}

	return producer
}

// getEnv è¯»å–ç¯å¢ƒå˜é‡ï¼Œæä¾›é»˜è®¤å€¼
func getEnv(key, defaultValue string) string {
	if value := os.Getenv(key); value != "" {
		return value
	}
	return defaultValue
}
